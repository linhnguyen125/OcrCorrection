step: 000010, train_loss: 4.8211, gpu_time: 4.445693492889404
step: 000020, train_loss: 4.7886, gpu_time: 4.028508901596069
step: 000030, train_loss: 4.7470, gpu_time: 3.937471628189087
step: 000040, train_loss: 4.6271, gpu_time: 4.297759532928467
step: 000050, train_loss: 4.5739, gpu_time: 3.962052583694458
step: 000060, train_loss: 4.1992, gpu_time: 4.209094524383545
step: 000070, train_loss: 3.7703, gpu_time: 3.861510992050171
step: 000080, train_loss: 3.2348, gpu_time: 4.077179908752441
step: 000090, train_loss: 2.9640, gpu_time: 4.224060535430908
step: 000100, train_loss: 2.8994, gpu_time: 4.011653661727905
val_loss: 2.7541, full_seq_acc: 0.0000, word_acc: 0.0000
step: 000110, train_loss: 2.6913, gpu_time: 4.361259460449219
step: 000120, train_loss: 2.6508, gpu_time: 4.410576820373535
step: 000130, train_loss: 2.5352, gpu_time: 4.184103965759277
step: 000140, train_loss: 2.4514, gpu_time: 4.3489649295806885
step: 000150, train_loss: 2.3905, gpu_time: 4.084979295730591
step: 000160, train_loss: 2.2558, gpu_time: 4.7899017333984375
step: 000170, train_loss: 2.2492, gpu_time: 4.80552864074707
step: 000180, train_loss: 2.2133, gpu_time: 4.276922225952148
step: 000190, train_loss: 2.1623, gpu_time: 4.102633714675903
step: 000200, train_loss: 2.0679, gpu_time: 4.543437242507935
val_loss: 2.0672, full_seq_acc: 0.0000, word_acc: 0.0003
step: 000210, train_loss: 2.0498, gpu_time: 4.319783449172974
step: 000220, train_loss: 2.0372, gpu_time: 3.9887287616729736
step: 000230, train_loss: 1.9771, gpu_time: 4.292953014373779
step: 000240, train_loss: 1.9455, gpu_time: 4.450498342514038
step: 000250, train_loss: 1.9123, gpu_time: 4.158280372619629
step: 000260, train_loss: 1.9028, gpu_time: 4.120079040527344
step: 000270, train_loss: 1.8224, gpu_time: 4.630296468734741
step: 000280, train_loss: 1.8251, gpu_time: 4.147627830505371
step: 000290, train_loss: 1.8214, gpu_time: 4.026670217514038
step: 000300, train_loss: 1.7683, gpu_time: 4.245140314102173
val_loss: 1.7747, full_seq_acc: 0.0000, word_acc: 0.0129
step: 000310, train_loss: 1.7375, gpu_time: 4.144862651824951
step: 000320, train_loss: 1.7217, gpu_time: 4.029170274734497
step: 000330, train_loss: 1.6787, gpu_time: 4.244385480880737
step: 000340, train_loss: 1.6143, gpu_time: 4.544996023178101
step: 000350, train_loss: 1.6281, gpu_time: 3.8373141288757324
step: 000360, train_loss: 1.5617, gpu_time: 4.632732152938843
step: 000370, train_loss: 1.5694, gpu_time: 4.2364277839660645
step: 000380, train_loss: 1.4472, gpu_time: 4.555666208267212
step: 000390, train_loss: 1.4597, gpu_time: 3.9907660484313965
step: 000400, train_loss: 1.3891, gpu_time: 4.143303394317627
val_loss: 1.3954, full_seq_acc: 0.0000, word_acc: 0.1029
step: 000410, train_loss: 1.3643, gpu_time: 4.361413240432739
step: 000420, train_loss: 1.2906, gpu_time: 4.517434120178223
step: 000430, train_loss: 1.2258, gpu_time: 4.535732269287109
step: 000440, train_loss: 1.2141, gpu_time: 4.412574768066406
step: 000450, train_loss: 1.1484, gpu_time: 4.181007146835327
step: 000460, train_loss: 1.1043, gpu_time: 4.474086761474609
step: 000470, train_loss: 1.0502, gpu_time: 4.209608793258667
step: 000480, train_loss: 1.0025, gpu_time: 4.145415782928467
step: 000490, train_loss: 0.9777, gpu_time: 4.1199586391448975
step: 000500, train_loss: 0.9526, gpu_time: 3.9622585773468018
val_loss: 0.9251, full_seq_acc: 0.0124, word_acc: 0.3449
step: 000510, train_loss: 0.8508, gpu_time: 4.478052616119385
step: 000520, train_loss: 0.8559, gpu_time: 4.044784784317017
step: 000530, train_loss: 0.8072, gpu_time: 4.239969253540039
step: 000540, train_loss: 0.7525, gpu_time: 4.4151082038879395
step: 000550, train_loss: 0.7586, gpu_time: 4.102675676345825
step: 000560, train_loss: 0.7059, gpu_time: 4.237861633300781
step: 000570, train_loss: 0.6878, gpu_time: 4.269756555557251
step: 000580, train_loss: 0.6530, gpu_time: 4.242918014526367
step: 000590, train_loss: 0.6471, gpu_time: 3.9103267192840576
step: 000600, train_loss: 0.5975, gpu_time: 4.4979331493377686
val_loss: 0.6229, full_seq_acc: 0.0586, word_acc: 0.5421
step: 000610, train_loss: 0.5846, gpu_time: 4.165724754333496
step: 000620, train_loss: 0.5663, gpu_time: 4.094526290893555
step: 000630, train_loss: 0.5498, gpu_time: 4.180618047714233
step: 000640, train_loss: 0.5224, gpu_time: 4.3358776569366455
step: 000650, train_loss: 0.5203, gpu_time: 3.988112211227417
step: 000660, train_loss: 0.4917, gpu_time: 4.109877824783325
step: 000670, train_loss: 0.4833, gpu_time: 3.9697296619415283
step: 000680, train_loss: 0.4772, gpu_time: 4.194120168685913
step: 000690, train_loss: 0.4541, gpu_time: 4.11142635345459
step: 000700, train_loss: 0.4575, gpu_time: 4.160590410232544
val_loss: 0.4687, full_seq_acc: 0.1195, word_acc: 0.6410
step: 000710, train_loss: 0.4307, gpu_time: 4.240041971206665
step: 000720, train_loss: 0.4336, gpu_time: 4.269218921661377
step: 000730, train_loss: 0.4056, gpu_time: 4.347472667694092
step: 000740, train_loss: 0.4112, gpu_time: 4.0196428298950195
step: 000750, train_loss: 0.3997, gpu_time: 4.529093503952026
step: 000760, train_loss: 0.4018, gpu_time: 4.036007642745972
step: 000770, train_loss: 0.3931, gpu_time: 4.394771337509155
step: 000780, train_loss: 0.3796, gpu_time: 4.369274854660034
step: 000790, train_loss: 0.3849, gpu_time: 4.08216667175293
step: 000800, train_loss: 0.3732, gpu_time: 4.278168439865112
val_loss: 0.4009, full_seq_acc: 0.1595, word_acc: 0.6913
step: 000810, train_loss: 0.3610, gpu_time: 4.243443727493286
step: 000820, train_loss: 0.3684, gpu_time: 4.255603313446045
step: 000830, train_loss: 0.3619, gpu_time: 4.58040976524353
step: 000840, train_loss: 0.3608, gpu_time: 4.307568788528442
step: 000850, train_loss: 0.3355, gpu_time: 4.595752000808716
step: 000860, train_loss: 0.3873, gpu_time: 3.833805561065674
step: 000870, train_loss: 0.3611, gpu_time: 4.1595776081085205
step: 000880, train_loss: 0.3356, gpu_time: 4.502443790435791
step: 000890, train_loss: 0.3395, gpu_time: 4.572053909301758
step: 000900, train_loss: 0.3578, gpu_time: 3.9149415493011475
val_loss: 0.3700, full_seq_acc: 0.1771, word_acc: 0.7104
step: 000910, train_loss: 0.3483, gpu_time: 4.21948504447937
step: 000920, train_loss: 0.3494, gpu_time: 4.234454393386841
step: 000930, train_loss: 0.3433, gpu_time: 4.434340715408325
step: 000940, train_loss: 0.3350, gpu_time: 4.467690706253052
step: 000950, train_loss: 0.3599, gpu_time: 4.011015176773071
step: 000960, train_loss: 0.3396, gpu_time: 4.502564430236816
step: 000970, train_loss: 0.3511, gpu_time: 3.9445247650146484
step: 000980, train_loss: 0.3412, gpu_time: 4.412987470626831
step: 000990, train_loss: 0.3396, gpu_time: 4.244615316390991
step: 001000, train_loss: 0.3475, gpu_time: 4.082490682601929
val_loss: 0.3678, full_seq_acc: 0.1777, word_acc: 0.7111
